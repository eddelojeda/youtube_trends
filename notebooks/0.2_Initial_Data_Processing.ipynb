{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db10e97a",
   "metadata": {},
   "source": [
    "## 0.2. Initial Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78985a59",
   "metadata": {},
   "source": [
    "This notebook contains the initial processing of the data in `data/raw/dataset.csv`. The steps performed in this notebook were added to the `youtube_trends/dataset.py` code as a processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e89821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 21:09:35.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myoutube_trends.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Users\\eddel\\OneDrive\\Documents\\MCD\\AAA\\youtube_trends\\venv\\src\\youtube-trends\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import emoji\n",
    "import torch\n",
    "import isodate\n",
    "import warnings\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "from langdetect import detect\n",
    "from PIL import Image, ImageStat\n",
    "from sklearn.decomposition import PCA\n",
    "from torchvision import models, transforms\n",
    "from deep_translator import GoogleTranslator\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from youtube_trends.config import RAW_DATA_DIR, INTERIM_DATA_DIR\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "415b42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(RAW_DATA_DIR / \"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6690c3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2857423 entries, 0 to 2857422\n",
      "Data columns (total 28 columns):\n",
      " #   Column                           Dtype  \n",
      "---  ------                           -----  \n",
      " 0   video_id                         object \n",
      " 1   video_published_at               object \n",
      " 2   video_trending__date             object \n",
      " 3   video_trending_country           object \n",
      " 4   channel_id                       object \n",
      " 5   video_title                      object \n",
      " 6   video_description                object \n",
      " 7   video_default_thumbnail          object \n",
      " 8   video_category_id                object \n",
      " 9   video_tags                       object \n",
      " 10  video_duration                   object \n",
      " 11  video_dimension                  object \n",
      " 12  video_definition                 object \n",
      " 13  video_licensed_content           object \n",
      " 14  video_view_count                 float64\n",
      " 15  video_like_count                 float64\n",
      " 16  video_comment_count              float64\n",
      " 17  channel_title                    object \n",
      " 18  channel_description              object \n",
      " 19  channel_custom_url               object \n",
      " 20  channel_published_at             object \n",
      " 21  channel_country                  object \n",
      " 22  channel_view_count               float64\n",
      " 23  channel_subscriber_count         float64\n",
      " 24  channel_have_hidden_subscribers  object \n",
      " 25  channel_video_count              float64\n",
      " 26  channel_localized_title          object \n",
      " 27  channel_localized_description    object \n",
      "dtypes: float64(6), object(22)\n",
      "memory usage: 610.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d1b1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['video_id', 'video_trending_country', 'video_description', 'video_dimension', 'video_definition', 'video_licensed_content', \n",
    "                  'channel_id',  'channel_title', 'channel_published_at', 'channel_description', 'channel_country', 'channel_video_count',\n",
    "                  'channel_have_hidden_subscribers', 'channel_localized_title', 'channel_localized_description'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36e550f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['video_published_at'] = pd.to_datetime(df['video_published_at'], errors='coerce').dt.tz_localize(None)\n",
    "df['video_trending__date'] = pd.to_datetime(df['video_trending__date'], errors='coerce').dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8f0d704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='video_published_at', ascending=False)\n",
    "start_date = df['video_published_at'].iloc[0] - relativedelta(days=1)\n",
    "df = df[df['video_published_at'] >= start_date]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec8833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['published_dayofweek'] = df['video_published_at'].dt.dayofweek\n",
    "df['published_hour'] = df['video_published_at'].dt.hour\n",
    "df['days_to_trend'] = (df['video_trending__date'] - df['video_published_at']).dt.days\n",
    "df = df[df['days_to_trend'] >= 0]\n",
    "df = df.drop(['video_trending__date'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d4660e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['video_title_length'] = df['video_title'].str.split().str.len()\n",
    "df['video_tag_count'] = df['video_tags'].str.split('|').str.len()\n",
    "df['video_tag_count'] = df['video_tag_count'].fillna(0)\n",
    "df = df.drop(['video_tags'], axis=1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bb60f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_duration(duration):\n",
    "    try:\n",
    "        return isodate.parse_duration(duration).total_seconds()\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102b8339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting durations: 100%|██████████| 398/398 [00:00<00:00, 199204.41it/s]\n"
     ]
    }
   ],
   "source": [
    "durations = df['video_duration'].fillna('').astype(str).tolist()\n",
    "with ThreadPoolExecutor() as executor: duration_secs = list(tqdm(executor.map(convert_duration, durations), total=len(durations), desc=\"Converting durations\"))\n",
    "df['video_duration'] = duration_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a84f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(title):\n",
    "    title = emoji.replace_emoji(title, replace='')\n",
    "    title = re.sub(r'[^\\w\\s]', '', title)\n",
    "    title = re.sub(r'\\s+', ' ', title)     \n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b202f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_translate(title):\n",
    "    try:\n",
    "        lang = detect(title)\n",
    "    except:\n",
    "        return '', ''\n",
    "    \n",
    "    if lang == 'en':\n",
    "        return 'en', title\n",
    "    try:\n",
    "        translated = GoogleTranslator(source='auto', target='en').translate(title)\n",
    "        return lang, translated\n",
    "    except:\n",
    "        return lang, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "015bb31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_titles_parallel(df):\n",
    "    titles = df['video_title'].fillna('').astype(str).tolist()\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        clean_titles = list(tqdm(executor.map(clean_title, titles), total=len(titles), desc=\"Cleaning titles\"))\n",
    "\n",
    "    languages = []\n",
    "    translations = []\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(detect_and_translate, title) for title in clean_titles]\n",
    "        for future in tqdm(futures, desc=\"Processing video title\"):\n",
    "            lang, translated = future.result()\n",
    "            languages.append(lang)\n",
    "            translations.append(translated)\n",
    "    \n",
    "    df['video_title_language'] = languages\n",
    "    df['video_title_translated'] = translations\n",
    "    df = df.drop(['video_title'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd4f22de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning titles: 100%|██████████| 398/398 [00:00<00:00, 398028.85it/s]\n",
      "Processing video title: 100%|██████████| 398/398 [00:04<00:00, 79.82it/s] \n"
     ]
    }
   ],
   "source": [
    "df = process_titles_parallel(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a11e1323",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['video_category_id'] = df['video_category_id'].str.replace(' ', '_')\n",
    "df = pd.get_dummies(df, columns=['video_category_id'])\n",
    "dummy_cols = [col for col in df.columns if col.startswith('video_category_id_')]\n",
    "df[dummy_cols] = df[dummy_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6fe7d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 398 entries, 127 to 526\n",
      "Data columns (total 28 columns):\n",
      " #   Column                                  Non-Null Count  Dtype         \n",
      "---  ------                                  --------------  -----         \n",
      " 0   video_published_at                      398 non-null    datetime64[ns]\n",
      " 1   video_default_thumbnail                 398 non-null    object        \n",
      " 2   video_duration                          398 non-null    float64       \n",
      " 3   video_view_count                        398 non-null    float64       \n",
      " 4   video_like_count                        398 non-null    float64       \n",
      " 5   video_comment_count                     398 non-null    float64       \n",
      " 6   channel_custom_url                      398 non-null    object        \n",
      " 7   channel_view_count                      398 non-null    float64       \n",
      " 8   channel_subscriber_count                398 non-null    float64       \n",
      " 9   published_dayofweek                     398 non-null    int32         \n",
      " 10  published_hour                          398 non-null    int32         \n",
      " 11  days_to_trend                           398 non-null    int64         \n",
      " 12  video_title_length                      398 non-null    int64         \n",
      " 13  video_tag_count                         398 non-null    float64       \n",
      " 14  video_title_language                    398 non-null    object        \n",
      " 15  video_title_translated                  398 non-null    object        \n",
      " 16  video_category_id_Autos_&_Vehicles      398 non-null    int64         \n",
      " 17  video_category_id_Comedy                398 non-null    int64         \n",
      " 18  video_category_id_Education             398 non-null    int64         \n",
      " 19  video_category_id_Entertainment         398 non-null    int64         \n",
      " 20  video_category_id_Film_&_Animation      398 non-null    int64         \n",
      " 21  video_category_id_Gaming                398 non-null    int64         \n",
      " 22  video_category_id_Music                 398 non-null    int64         \n",
      " 23  video_category_id_News_&_Politics       398 non-null    int64         \n",
      " 24  video_category_id_People_&_Blogs        398 non-null    int64         \n",
      " 25  video_category_id_Pets_&_Animals        398 non-null    int64         \n",
      " 26  video_category_id_Science_&_Technology  398 non-null    int64         \n",
      " 27  video_category_id_Sports                398 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(7), int32(2), int64(14), object(4)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35a66c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_thumbnail(thumbnail_url, idx, class_names, model, pbar):\n",
    "    results = model(thumbnail_url)\n",
    "    class_ids = results.xyxy[0][:, 5].int().tolist()\n",
    "    detections = np.zeros(len(class_names), dtype=int)\n",
    "    for cls_id in set(class_ids):\n",
    "        detections[int(cls_id)] = 1\n",
    "    pbar.update(1)\n",
    "    return idx, detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a810089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_thumbnail(thumbnail_url, idx, class_names, model, pbar, img_size=640):\n",
    "    try:\n",
    "        response = requests.get(thumbnail_url, timeout=5)\n",
    "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        img_resized = img.resize((img_size, img_size))\n",
    "        results = model(img_resized, size=img_size)\n",
    "        detected_classes = [class_names[int(cls)] for cls in results.pred[0][:, -1].cpu().numpy()]\n",
    "        detections = [1 if name in detected_classes else 0 for name in class_names]\n",
    "        return idx, detections\n",
    "    except Exception as e:\n",
    "        print(f\"Error en {thumbnail_url}: {e}\")\n",
    "        return idx, [0] * len(class_names)\n",
    "    finally:\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "691b4fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  thumbnail_parallel_detect(df):\n",
    "    thumbnail_urls = df['video_default_thumbnail'].values\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'yolov5n', verbose=False).to(device)\n",
    "    class_names = ['thumbnail_' + name.replace(' ', '_') for name in model.names.values()]\n",
    "    detections_array = np.zeros((len(thumbnail_urls), len(class_names)), dtype=int)\n",
    "    \n",
    "    with tqdm(total=len(thumbnail_urls), desc=\"Processing thumbnails class\") as pbar:\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = [\n",
    "                executor.submit(detect_thumbnail, thumbnail_url, idx, class_names, model, pbar)\n",
    "                for idx, thumbnail_url in enumerate(thumbnail_urls)\n",
    "            ]\n",
    "            for future in futures:\n",
    "                idx, detections = future.result()\n",
    "                detections_array[idx] = detections\n",
    "    \n",
    "    detections_df = pd.DataFrame(detections_array, columns=class_names)\n",
    "    detections_df['video_default_thumbnail'] = df['video_default_thumbnail'].values\n",
    "    detection_means = (detections_df == detections_df.iloc[0]).mean()\n",
    "    detection_to_drop = detection_means[(detection_means > 0.95) | (detection_means < 0.05)].index\n",
    "    detections_df = detections_df.drop(columns=detection_to_drop)\n",
    "    df = pd.concat([df, detections_df.iloc[:, :-1]], axis=1)\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24a554c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2025-4-28 Python-3.12.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs\n",
      "Adding AutoShape... \n",
      "Processing thumbnails class: 100%|██████████| 398/398 [00:05<00:00, 69.42it/s]\n"
     ]
    }
   ],
   "source": [
    "df = thumbnail_parallel_detect(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7730c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thumbnail_stats(thumbnail_url, idx, pbar):\n",
    "    response = requests.get(thumbnail_url, timeout=10)\n",
    "    img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "    stat = ImageStat.Stat(img)\n",
    "\n",
    "    brightness = sum(stat.mean) / 3\n",
    "    contrast = sum(stat.stddev) / 3\n",
    "    hsv = np.array(img.convert('HSV'))\n",
    "    saturation = hsv[:, :, 1].mean() / 255\n",
    "\n",
    "    pbar.update(1)\n",
    "    return idx, [brightness, contrast, saturation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6da51d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thumbnails_stats_parallel(df):\n",
    "    thumbnail_urls = df['video_default_thumbnail'].values\n",
    "    stats_array = np.zeros((len(thumbnail_urls), 3), dtype=float)\n",
    "\n",
    "    with tqdm(total=len(thumbnail_urls), desc=\"Processing thumbnails stats\") as pbar:\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = [\n",
    "                executor.submit(thumbnail_stats, thumbnail_url, idx, pbar) \n",
    "                for idx, thumbnail_url in enumerate(thumbnail_urls)\n",
    "            ]\n",
    "            for future in futures:\n",
    "                idx, stats = future.result()\n",
    "                stats_array[idx] = stats\n",
    "\n",
    "    stats_df = pd.DataFrame(stats_array, columns=['thumbnail_brightness', 'thumbnail_contrast', 'thumbnail_saturation'])\n",
    "    stats_df['video_default_thumbnail'] = thumbnail_urls\n",
    "    df = pd.concat([df, stats_df.iloc[:, :-1]], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90cdd343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing thumbnails stats: 100%|██████████| 271/271 [00:02<00:00, 90.36it/s] \n"
     ]
    }
   ],
   "source": [
    "df = thumbnails_stats_parallel(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e89e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_thumbnail(thumbnail_url, idx, transform, model, pbar):\n",
    "    try:\n",
    "        response = requests.get(thumbnail_url, timeout=5)\n",
    "        img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "        img = transform(img).unsqueeze(0).to(device)  \n",
    "        with torch.no_grad():\n",
    "            features = model.features(img)\n",
    "            features = features.mean([2, 3]).squeeze().cpu().numpy() \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {thumbnail_url}: {e}\")\n",
    "        features = np.full((1280,), np.nan) \n",
    "    pbar.update(1)\n",
    "    return idx, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a8fac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thumbnail_parallel_embeddings(df):\n",
    "    thumbnail_urls = df['video_default_thumbnail'].values\n",
    "    \n",
    "    model = models.mobilenet_v2(pretrained=True)\n",
    "    model.eval()\n",
    "    model = model.to(device) \n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    n_samples = len(thumbnail_urls)\n",
    "    embedding_dim = 1280  \n",
    "    embeddings_array = np.zeros((n_samples, embedding_dim), dtype=np.float32)\n",
    "\n",
    "    with tqdm(total=n_samples, desc=\"Extracting thumbnails embeddings\") as pbar:\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = [\n",
    "                executor.submit(embedding_thumbnail, url, idx, transform, model, pbar)\n",
    "                for idx, url in enumerate(thumbnail_urls)\n",
    "            ]\n",
    "            for future in futures:\n",
    "                idx, embedding = future.result()\n",
    "                embeddings_array[idx] = embedding\n",
    "\n",
    "    valid_rows = ~np.isnan(embeddings_array).any(axis=1) \n",
    "    embeddings_array = embeddings_array[valid_rows] \n",
    "\n",
    "    pca_complete = PCA().fit(embeddings_array)\n",
    "    cumulative_variance = np.cumsum(pca_complete.explained_variance_ratio_)\n",
    "    n_components = np.searchsorted(cumulative_variance, 0.70) + 1 \n",
    "    n_components = min(n_components, 40)\n",
    "    pca = PCA(n_components=n_components)  \n",
    "    reduced_embeddings = pca.fit_transform(embeddings_array)\n",
    "\n",
    "    embed_cols = [f'thumb_emb_{i}' for i in range(reduced_embeddings.shape[1])]  \n",
    "    embeddings_df = pd.DataFrame(reduced_embeddings, columns=embed_cols)\n",
    "    df = pd.concat([df.reset_index(drop=True), embeddings_df], axis=1)\n",
    "    df = df.dropna()\n",
    "\n",
    "    return pd.concat([df.reset_index(drop=True), embeddings_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2568ea32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting thumbnails embeddings:  97%|█████████▋| 387/398 [00:04<00:00, 396.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Error procesando nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting thumbnails embeddings: 100%|██████████| 398/398 [00:04<00:00, 94.45it/s] \n"
     ]
    }
   ],
   "source": [
    "df = thumbnail_parallel_embeddings(df)\n",
    "df = df.drop(['video_default_thumbnail'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1caeeda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271 entries, 0 to 270\n",
      "Data columns (total 71 columns):\n",
      " #   Column                                  Non-Null Count  Dtype         \n",
      "---  ------                                  --------------  -----         \n",
      " 0   video_published_at                      144 non-null    datetime64[ns]\n",
      " 1   video_duration                          144 non-null    float64       \n",
      " 2   video_view_count                        144 non-null    float64       \n",
      " 3   video_like_count                        144 non-null    float64       \n",
      " 4   video_comment_count                     144 non-null    float64       \n",
      " 5   channel_custom_url                      144 non-null    object        \n",
      " 6   channel_view_count                      144 non-null    float64       \n",
      " 7   channel_subscriber_count                144 non-null    float64       \n",
      " 8   published_dayofweek                     144 non-null    float64       \n",
      " 9   published_hour                          144 non-null    float64       \n",
      " 10  days_to_trend                           144 non-null    float64       \n",
      " 11  video_title_length                      144 non-null    float64       \n",
      " 12  video_tag_count                         144 non-null    float64       \n",
      " 13  video_title_language                    144 non-null    object        \n",
      " 14  video_title_translated                  144 non-null    object        \n",
      " 15  video_category_id_Autos_&_Vehicles      144 non-null    float64       \n",
      " 16  video_category_id_Comedy                144 non-null    float64       \n",
      " 17  video_category_id_Education             144 non-null    float64       \n",
      " 18  video_category_id_Entertainment         144 non-null    float64       \n",
      " 19  video_category_id_Film_&_Animation      144 non-null    float64       \n",
      " 20  video_category_id_Gaming                144 non-null    float64       \n",
      " 21  video_category_id_Music                 144 non-null    float64       \n",
      " 22  video_category_id_News_&_Politics       144 non-null    float64       \n",
      " 23  video_category_id_People_&_Blogs        144 non-null    float64       \n",
      " 24  video_category_id_Pets_&_Animals        144 non-null    float64       \n",
      " 25  video_category_id_Science_&_Technology  144 non-null    float64       \n",
      " 26  video_category_id_Sports                144 non-null    float64       \n",
      " 27  thumbnail_person                        144 non-null    float64       \n",
      " 28  thumbnail_brightness                    144 non-null    float64       \n",
      " 29  thumbnail_contrast                      144 non-null    float64       \n",
      " 30  thumbnail_saturation                    144 non-null    float64       \n",
      " 31  thumb_emb_0                             144 non-null    float32       \n",
      " 32  thumb_emb_1                             144 non-null    float32       \n",
      " 33  thumb_emb_2                             144 non-null    float32       \n",
      " 34  thumb_emb_3                             144 non-null    float32       \n",
      " 35  thumb_emb_4                             144 non-null    float32       \n",
      " 36  thumb_emb_5                             144 non-null    float32       \n",
      " 37  thumb_emb_6                             144 non-null    float32       \n",
      " 38  thumb_emb_7                             144 non-null    float32       \n",
      " 39  thumb_emb_8                             144 non-null    float32       \n",
      " 40  thumb_emb_9                             144 non-null    float32       \n",
      " 41  thumb_emb_10                            144 non-null    float32       \n",
      " 42  thumb_emb_11                            144 non-null    float32       \n",
      " 43  thumb_emb_12                            144 non-null    float32       \n",
      " 44  thumb_emb_13                            144 non-null    float32       \n",
      " 45  thumb_emb_14                            144 non-null    float32       \n",
      " 46  thumb_emb_15                            144 non-null    float32       \n",
      " 47  thumb_emb_16                            144 non-null    float32       \n",
      " 48  thumb_emb_17                            144 non-null    float32       \n",
      " 49  thumb_emb_18                            144 non-null    float32       \n",
      " 50  thumb_emb_19                            144 non-null    float32       \n",
      " 51  thumb_emb_0                             271 non-null    float32       \n",
      " 52  thumb_emb_1                             271 non-null    float32       \n",
      " 53  thumb_emb_2                             271 non-null    float32       \n",
      " 54  thumb_emb_3                             271 non-null    float32       \n",
      " 55  thumb_emb_4                             271 non-null    float32       \n",
      " 56  thumb_emb_5                             271 non-null    float32       \n",
      " 57  thumb_emb_6                             271 non-null    float32       \n",
      " 58  thumb_emb_7                             271 non-null    float32       \n",
      " 59  thumb_emb_8                             271 non-null    float32       \n",
      " 60  thumb_emb_9                             271 non-null    float32       \n",
      " 61  thumb_emb_10                            271 non-null    float32       \n",
      " 62  thumb_emb_11                            271 non-null    float32       \n",
      " 63  thumb_emb_12                            271 non-null    float32       \n",
      " 64  thumb_emb_13                            271 non-null    float32       \n",
      " 65  thumb_emb_14                            271 non-null    float32       \n",
      " 66  thumb_emb_15                            271 non-null    float32       \n",
      " 67  thumb_emb_16                            271 non-null    float32       \n",
      " 68  thumb_emb_17                            271 non-null    float32       \n",
      " 69  thumb_emb_18                            271 non-null    float32       \n",
      " 70  thumb_emb_19                            271 non-null    float32       \n",
      "dtypes: datetime64[ns](1), float32(40), float64(27), object(3)\n",
      "memory usage: 108.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b7b39db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(INTERIM_DATA_DIR / 'dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
